2/25
====

The dragon book!

super computing: cooling!

purple dragon: the most evil dragon

project: 45%   # compiler implementation: C--
midterm 25%
final 25%
quiz: 5%

we have 6 check point for the project

automatic translation & optimization

the traditional view is a narrow view

translation!

silicon compiler: Ex. verilog to VLSI layout

台灣芯悲劇 XD

target machine mode
    pure machine code (ISA)
        assembly language format, relocatable binary format, load-and-go-format
    augmented machine code (ABI)
    bytecode(virtual machine code)

P-code (Pascal)
[wiki](http://en.wikipedia.org/wiki/P-code_machine)

VISA -> virtual ISA


two parts of compilation
    analysis: tokenise, AST, ...
    synthesis: codegen, optimize ...

the difference between interpreter and compiler


interpreter avoids the synthesis part but involves large overhead(time, space)
    portable, dynamic typing
    better diagnostics

hybrid compiler / JIT

a head of time / JIT (adaptive translation) -> profiling


lexical analysis (linear analysis)
syntax analysis (hierarchical analysis)
semantic analysis

codegen
opt



syntax directed compiler

lexical analysis:  error if unrecognized token
syntax analysis: error if can't build ASTs
semantic analysis: type checking! insert type conversion to AST

phases of a compiler

six phases: lexical, syntax, semantic, IR codegen, optimizer, target codegen
symbol table manager / error handler and recovery

optimization: machine dependent optimization / machine independent optimization

setroation elesmatic



3/4
====

review the 6 phases

there's no real registeer in IR, use virtual registeer instead

lexical analyis: FSA (Finite State Automata)
codegen: Tree matching

frondend / backend

common backend compiling system
    variety languages -> IR -> optimizer -> target machine codegen

retargetable compiler
    one language front-end -> IR -> machine independent optimization -> different machine codegen

without IR -> N by M

syntax (structure)
semantics (meaning)

syntax is usually defined by CFG (context free grammar)
semantics: such as type compatibility, scoping rules, context-sensitive

static semantics
    attribute grammars
runtime semantics
    natural semantics
    axiomatic semantics
    denotational semantics

    Ex. assertion

imprecise semantics challenges
    sometimes definitions in the specification of the language are not well defined
    unreachable statements (control may reach end of non-void function)



requirements for a successful languages
many machines failed because they are hard to compile/optimize for
    intel 860    IBM cell    cray-2

codegen
parsing
code optimization
parallelization

instruction parallelism!

cross compilation



ch 2.
design of a simple compiler

type check!

AC program char stream -> lexical analyzer -> token stream -> syntax directed translator -> DC code

AC-to-DC compiler



3/11
====

my laptop ran out of power QQ

tokenization
parsing

parsing tree
    root: start sumbol
    leaf: token or empty
    internal node: non-terminal

ambiguous

grammar: can be recursive, but notice if any ambiguity
    associative operators


associativity

<expr> -> <primary> { <op> <primary> }     Ex. A = {+ B} {+ C}
<expr> -> { <primary> <op> } <primary>     Ex. {A = } { B =} C

<expr> -> <expr> <op> <primary>  : left
<expr> -> <primary> <op> <expr>  : right

focus on what is repeating
    op primary -> left associativ
    primary op -> right associative


precedence of operators
    create two non-terminals for the two levels of precedence
    practice: give a weight (priority) to operators, using a stack to maintain that
    operator precedence parsing

parse tree / syntax tree

top down
bottom up

top down: known as predictive parsing, may need to modify productions
bottom up: less restrictions on grammars, more commonly used in production compilers

recursive descent parsing

for each non-terminal has a parsing procedure
for symbols on RHS, to match a non-terminal A, call the parsing procedure A, to match a terminal t, all math(t)

lookahead
  ll(K): need K lookaheads to determine the path (uniquely)
  the next_token is used to determine what production to apply
  first(alpha): grab the first token out

not all CGF have the property of predictive parsing

productions sharing the same LHS can be distinguished by the FIRST() set.
with the above property is called  LL(1) grammar
LL(1) stands for left-to-right, left-most derivation, only one lookahead token is required in predictive parsing


try LL(1) as possible otherwise, LR parsing

left recursion removal

A -> Aa | b

{b, ba, baa, baaa, ...}

A -> bR
R -> aR | e

(e for empty)


we need to make left recursion "right"

LL -> top down
LR -> bottom up

left recursion & left factoring

left recursion is good to bottom up parsing, but bad to predictive parsing







3/18
=====

AST after semeantic analysis

in symbol table, we always use a union to represent different types

type chacking

symbol reference

using visitor pattern

codegen in AC-DC compiler

temporaries
in real compilers, registers are typically used as temporaries


register is not memory

locality / parallelism

move computation to data or move data to computation

top down parsing: build the parse tree top down left to right
recursive descent: one way to implement top-down parsing, may need to backtrack
predictive parsing: recursive descent parsing when the CFG is LL(k), no backtracking

semantic routines
semantic records

syntax directed definition: CFG + semantics routines
(semantic attributes + semantic rules)


source program <-char stream (maybe push back)-> lexical analyzer <-pass token, attribute value, get next-> parser




